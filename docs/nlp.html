

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="The Natural Language Processing (NLP) library" name="description" />
<meta content="Python, TDT, NLP" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3. Natural Language Processing (NLP) &mdash; EvenTDT 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Automatic Participant Detection (APD)" href="apd.html" />
    <link rel="prev" title="2. Vector Space Model (VSM)" href="vsm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> EvenTDT
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="config.html">0. Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">1. Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="vsm.html">2. Vector Space Model (VSM)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. Natural Language Processing (NLP)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-nlp.document">Documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-nlp.tokenizer">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-nlp.term_weighting">Term-Weighting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp.term_weighting.tf">Common Term-Weighting Schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp.term_weighting.local_schemes.boolean">Local Term-Weighting Schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp.term_weighting.global_schemes.filler">Global Term-Weighting Schemes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="apd.html">4. Automatic Participant Detection (APD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="other.html">5. Other</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">EvenTDT</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>3. Natural Language Processing (NLP)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/nlp.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="natural-language-processing-nlp">
<h1>3. Natural Language Processing (NLP)<a class="headerlink" href="#natural-language-processing-nlp" title="Permalink to this headline">¶</a></h1>
<p>Documents find their basis in the Vector Space Model (VSM).
For this reason, EvenTDT’s documents are based on the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.vsm.vector.Vector</span></code> class.
EvenTDT adds functionality to make it easier to work with documents, including by storing the original text.
Keep reading to learn more about the different NLP classes available in EvenTDT.</p>
<span class="target" id="module-nlp"></span><div class="section" id="module-nlp.document">
<span id="documents"></span><h2>Documents<a class="headerlink" href="#module-nlp.document" title="Permalink to this headline">¶</a></h2>
<p>Documents are the basis in NLP tasks.
The <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code> class builds on the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.vsm.vector.Vector</span></code> class.
In addition to the normal VSM functionality, it stores the original text for any later changes.</p>
<p>Creating documents is a two-step process.
First, the text needs to be converted into tokens using the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.tokenizer.Tokenizer</span></code> class.
Second, those tokens need to be weighted using a <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.TermWeightingScheme</span></code>, transforming them into document features, or vector dimensions.</p>
<dl class="class">
<dt id="nlp.document.Document">
<em class="property">class </em><code class="sig-prename descclassname">nlp.document.</code><code class="sig-name descname">Document</code><span class="sig-paren">(</span><em class="sig-param">text=''</em>, <em class="sig-param">dimensions=None</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code> class is based on the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.vsm.vector.Vector</span></code> class. class.
The main addition is the text field for any later changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The document’s original text.</p>
</dd>
</dl>
<dl class="method">
<dt id="nlp.document.Document.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">text=''</em>, <em class="sig-param">dimensions=None</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the document with the text and optional dimensions.
Any other arguments or keyword arguments are passed on to the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.vsm.vector.Vector</span></code> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – The document’s text.</p></li>
<li><p><strong>dimensions</strong> (<em>list</em><em> or </em><em>dict</em>) – The initial dimensions of the document.
If a list is provided, it is assumed that they are tokens.
The dimensions are then created from this list using the given scheme.</p></li>
<li><p><strong>scheme</strong> (None or <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.TermWeighting</span></code>) – The term-weighting scheme that is used to convert the tokens into dimensions.
If <cite>None</cite> is given, the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.TermWeighting.TF</span></code> term-weighting scheme is used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.to_array">
<code class="sig-name descname">to_array</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.to_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Export the document as an associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The document as an associative array.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.from_array">
<em class="property">static </em><code class="sig-name descname">from_array</code><span class="sig-paren">(</span><em class="sig-param">array</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.from_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the document from the given associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>array</strong> (<em>dict</em>) – The associative array with the attributes to create the document.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of an object with the same attributes stored in the object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">vector.nlp.document.Document</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.concatenate">
<em class="property">static </em><code class="sig-name descname">concatenate</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">tokenizer</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenate all of the documents that are provided as arguments.
The function first concatenates the text of all the documents.
Then, it tokenizes the concatenated and creates a document from it.</p>
<p>Any additional keyword arguments are passed on to the Document constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheme</strong> (<a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp.term_weighting.scheme.TermWeightingScheme</span></code></a>) – The term-weighting scheme to use to create the concatenated document.</p></li>
<li><p><strong>tokenizer</strong> (<a class="reference internal" href="#nlp.tokenizer.Tokenizer" title="nlp.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp.tokenizer.Tokenizer</span></code></a>) – The tokenizer to use to construct the concatenated document.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new document representing the concatenated documents.
The document is not normalized.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp.document.Document</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.tokenizer">
<span id="tokenization"></span><h2>Tokenization<a class="headerlink" href="#module-nlp.tokenizer" title="Permalink to this headline">¶</a></h2>
<p>The tokenizer takes plain text and splits it into a list of tokens.
Tokens are the equivalent of document features, or vector dimensions.</p>
<p>Tokenization is the first of two steps to create a <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code>.
The second step is term-weighting using a <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.TermWeightingScheme</span></code>.
A term-weighting scheme receives tokens and creates a weighted <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code> out of them.</p>
<p>The tokenizer takes its settings in the constructor.
All tokenization happens using the <code class="xref py py-func docutils literal notranslate"><span class="pre">eventdt.nlp.tokenizer.Tokenizer.tokenize()</span></code> function.
In this way, all documents are tokenized in the same way.
Creating and using a tokenizer is very simple:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">stem</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">split_hashtags</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">tokenize</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Stemming is based on, and requires, NLTK.</p>
</div>
<dl class="class">
<dt id="nlp.tokenizer.Tokenizer">
<em class="property">class </em><code class="sig-prename descclassname">nlp.tokenizer.</code><code class="sig-name descname">Tokenizer</code><span class="sig-paren">(</span><em class="sig-param">remove_mentions=True</em>, <em class="sig-param">remove_hashtags=False</em>, <em class="sig-param">split_hashtags=True</em>, <em class="sig-param">remove_numbers=True</em>, <em class="sig-param">remove_urls=True</em>, <em class="sig-param">remove_alt_codes=True</em>, <em class="sig-param">normalize_words=False</em>, <em class="sig-param">character_normalization_count=3</em>, <em class="sig-param">case_fold=True</em>, <em class="sig-param">remove_punctuation=True</em>, <em class="sig-param">remove_unicode_entities=False</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">stopwords=None</em>, <em class="sig-param">stem=True</em>, <em class="sig-param">normalize_special_characters=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>The tokenizer takes in strings and converts them into tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stemmer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.stem.porter.PorterStemmer</span></code>) – The Porter Stemmer used by the class.</p></li>
<li><p><strong>remove_mentions</strong> (<em>bool</em>) – A boolean indicating whether mentions (&#64;) should be removed.</p></li>
<li><p><strong>remove_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be removed.</p></li>
<li><p><strong>split_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be normalized.
This converts hashtags of the type #HashTag to <cite>Hash Tag</cite>, based on camel-case.</p></li>
<li><p><strong>remove_numbers</strong> (<em>bool</em>) – A boolean indicating whether numbers should be removed.</p></li>
<li><p><strong>remove_urls</strong> (<em>bool</em>) – A boolean indicating whether URLs should be removed.</p></li>
<li><p><strong>remove_alt_codes</strong> (<em>bool</em>) – A boolean indicating whether ALT-codes should be removed.</p></li>
<li><p><strong>normalize_words</strong> (<em>bool</em>) – A boolean indicating whether words should be normalized.
This removes repeated characters.
The number of repeated characters that are removed is controlled using the <cite>character_normalization_count</cite> parameter.</p></li>
<li><p><strong>character_normalization_count</strong> (<em>int</em>) – The number of times a character is repeated before they are reduced to one.</p></li>
<li><p><strong>case_fold</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be case-folded to lowercase.</p></li>
<li><p><strong>remove_punctuation</strong> (<em>bool</em>) – A boolean indicating whether punctuation should be removed.</p></li>
<li><p><strong>remove_unicode_entities</strong> (<em>bool</em>) – A boolean indicating whether unicode entities should be removed.</p></li>
<li><p><strong>min_length</strong> (<em>int</em>) – The minimum length of tokens that should be retained.</p></li>
<li><p><strong>stopwords</strong> (<em>list</em>) – A list of stopwords.
Stopwords are common words that are removed from token lists.
This is based on the assumption that they are not very expressive.
Normally, stopwords are provided as a list, and then converted into a dict, where the stopwords are the keys.
This approach is adopted since Python uses hashing to check whether a key is in a dict.
However, they may also be provided as a dict directly.</p></li>
<li><p><strong>stem</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be stemmed.</p></li>
<li><p><strong>normalize_special_characters</strong> (<em>bool</em>) – A boolean indicating whether accents should be removed and replaced with simple unicode characters.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nlp.tokenizer.Tokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">remove_mentions=True</em>, <em class="sig-param">remove_hashtags=False</em>, <em class="sig-param">split_hashtags=True</em>, <em class="sig-param">remove_numbers=True</em>, <em class="sig-param">remove_urls=True</em>, <em class="sig-param">remove_alt_codes=True</em>, <em class="sig-param">normalize_words=False</em>, <em class="sig-param">character_normalization_count=3</em>, <em class="sig-param">case_fold=True</em>, <em class="sig-param">remove_punctuation=True</em>, <em class="sig-param">remove_unicode_entities=False</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">stopwords=None</em>, <em class="sig-param">stem=True</em>, <em class="sig-param">normalize_special_characters=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>remove_mentions</strong> (<em>bool</em>) – A boolean indicating whether mentions (&#64;) should be removed.</p></li>
<li><p><strong>remove_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be removed.</p></li>
<li><p><strong>split_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be normalized.
This converts hashtags of the type #HashTag to <cite>Hash Tag</cite>, based on camel-case.</p></li>
<li><p><strong>remove_numbers</strong> (<em>bool</em>) – A boolean indicating whether numbers should be removed.</p></li>
<li><p><strong>remove_urls</strong> (<em>bool</em>) – A boolean indicating whether URLs should be removed.</p></li>
<li><p><strong>remove_alt_codes</strong> (<em>bool</em>) – A boolean indicating whether ALT-codes should be removed.</p></li>
<li><p><strong>normalize_words</strong> (<em>bool</em>) – A boolean indicating whether words should be normalized.
This removes repeated characters.
The number of repeated characters that are removed is controlled using the <cite>character_normalization_count</cite> parameter.</p></li>
<li><p><strong>character_normalization_count</strong> (<em>int</em>) – The number of times a character is repeated before they are reduced to one.</p></li>
<li><p><strong>case_fold</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be case-folded to lowercase.</p></li>
<li><p><strong>remove_punctuation</strong> (<em>bool</em>) – A boolean indicating whether punctuation should be removed.</p></li>
<li><p><strong>remove_unicode_entities</strong> (<em>bool</em>) – A boolean indicating whether unicode entities should be removed.
Note that this also includes emojis.</p></li>
<li><p><strong>min_length</strong> (<em>int</em>) – The minimum length of tokens that should be retained.</p></li>
<li><p><strong>stopwords</strong> (<em>list</em>) – A list of stopwords: common words that are removed from token lists.
This is based on the assumption that they are not very expressive.
Normally, stopwords are provided as a list, and then converted into a dict, where the stopwords are the keys.
This approach is adopted since Python uses hashing to check whether a key is in a dict.
However, they may also be provided as a dict directly.</p></li>
<li><p><strong>stem</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be stemmed.</p></li>
<li><p><strong>normalize_special_characters</strong> (<em>bool</em>) – A boolean indicating whether accents should be removed and replaced with simple unicode characters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.tokenizer.Tokenizer.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize the given text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to tokenize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of tokens.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.tokenizer.Tokenizer._split_hashtags">
<code class="sig-name descname">_split_hashtags</code><span class="sig-paren">(</span><em class="sig-param">string</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer._split_hashtags" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the hashtags in the given string based on camel-case notation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>string</strong> (<em>str</em>) – The string to normalize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The normalized string.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.tokenizer.Tokenizer.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.tokenizer.Tokenizer.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.term_weighting">
<span id="term-weighting"></span><h2>Term-Weighting<a class="headerlink" href="#module-nlp.term_weighting" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-nlp.term_weighting.scheme"></span><p>Term-weighting schemes give different weights to different terms in a document.
Traditionally, term-weighting schemes have at least a local and global component.</p>
<dl class="class">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.scheme.</code><code class="sig-name descname">TermWeightingScheme</code><span class="sig-paren">(</span><em class="sig-param">local_scheme</em>, <em class="sig-param">global_scheme</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="Permalink to this definition">¶</a></dt>
<dd><p>This class defines a list of properties that all term-weighting schemes must have.
The class can be instantiated by providing a local term-weighting scheme and a global term-weighting scheme.
The scheme then multiplies the scores of each to <code class="xref py py-func docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.TermWeightingScheme.create()</span></code> a <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.Scheme</span></code>) – The local term-weighting scheme.</p></li>
<li><p><strong>global_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.Scheme</span></code>) – The global term-weighting scheme.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">local_scheme</em>, <em class="sig-param">global_scheme</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>A term-weighting scheme is made up of a local component and a global component.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.Scheme</span></code>) – The local term-weighting scheme.</p></li>
<li><p><strong>global_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.Scheme</span></code>) – The global term-weighting scheme.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme.create">
<code class="sig-name descname">create</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme.create" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a document from the given tokens.
The function multiplies the local and global scores of each token.
The function accepts other arguments or keyword arguments, such as the document text or attributes.
These are passed on to the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – A list of tokens that can be converted into dimensions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new document with the given tokens as the dimensions.
The dimensions’ weights depend on the term-weighting scheme.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.document.Document</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp.term_weighting.scheme.SchemeScorer">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.scheme.</code><code class="sig-name descname">SchemeScorer</code><a class="headerlink" href="#nlp.term_weighting.scheme.SchemeScorer" title="Permalink to this definition">¶</a></dt>
<dd><p>A scheme is used to score documents’ tokens.
It is important to distinguish between <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.TermWeightingScheme</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.SchemeScorer</span></code>.
The former is a complete term-weighting scheme that takes local and global scheme scorers.
The latter is the actual scorer.
A <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.SchemeScorer</span></code> is a component of a term-weighting scheme.
A <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.scheme.TermWeightingScheme</span></code> combines local and global scorers to create documents.</p>
<dl class="method">
<dt id="nlp.term_weighting.scheme.SchemeScorer.score">
<em class="property">abstract </em><code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.SchemeScorer.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given list of tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.term_weighting.scheme.SchemeScorer.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.term_weighting.scheme.SchemeScorer.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<div class="section" id="module-nlp.term_weighting.tf">
<span id="common-term-weighting-schemes"></span><h3>Common Term-Weighting Schemes<a class="headerlink" href="#module-nlp.term_weighting.tf" title="Permalink to this headline">¶</a></h3>
<p>The term frequency term-weighting scheme is used when there is no need for a global scheme.
The term frequency <span class="math notranslate nohighlight">\(tf_{t,d}\)</span> of a feature <span class="math notranslate nohighlight">\(t\)</span> is equivalent to its frequency <span class="math notranslate nohighlight">\(f_{t,d}\)</span> in document <span class="math notranslate nohighlight">\(d\)</span>:</p>
<div class="math notranslate nohighlight">
\[tf_{t,d} = f_{t,d}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.tf.TF">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.tf.</code><code class="sig-name descname">TF</code><a class="headerlink" href="#nlp.term_weighting.tf.TF" title="Permalink to this definition">¶</a></dt>
<dd><p>The TF scheme is used when there is no need for a global scheme.</p>
<dl class="method">
<dt id="nlp.term_weighting.tf.TF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tf.TF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the TF-IDF term-weighting scheme by supplying the TF and filler schemes.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.term_weighting.tfidf"></span><p>The Term Frequency-Inverse Document Frequency (TF-IDF) term-weighting scheme is one of the most popular schemes.
The scheme promotes features that appear commonly in a document, but rarely outside of it.
The TFIDF is simply the multiplication of the <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.local_schemes.tf.TF</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">eventdt.nlp.term_weighting.global_schemes.idf.IDF</span></code> term-weighting schemes:
The weight <span class="math notranslate nohighlight">\(tfidf_{t,d}\)</span> of term <span class="math notranslate nohighlight">\(idf_{t}\)</span> in document <span class="math notranslate nohighlight">\(d\)</span> is computed as follows:</p>
<div class="math notranslate nohighlight">
\[tfidf_{t,d} = tf_{t,d} \cdot idf_{t}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.tfidf.TFIDF">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.tfidf.</code><code class="sig-name descname">TFIDF</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tfidf.TFIDF" title="Permalink to this definition">¶</a></dt>
<dd><p>The Term Frequency-Inverse Document Frequency (TF-IDF) term-weighting scheme is one of the most popular schemes.
The scheme promotes features that appear commonly in a document, but rarely outside of it.</p>
<dl class="method">
<dt id="nlp.term_weighting.tfidf.TFIDF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tfidf.TFIDF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the TF-IDF term-weighting scheme by supplying the TF and IDF schemes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idf</strong> (<em>dict</em>) – The IDF table used in conjunction with term weighting.
The keys are the terms, and the corresponding values are the number of documents in which they appear.</p></li>
<li><p><strong>documents</strong> (<em>int</em>) – The number of documents in the IDF table.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.term_weighting.local_schemes.boolean">
<span id="local-term-weighting-schemes"></span><h3>Local Term-Weighting Schemes<a class="headerlink" href="#module-nlp.term_weighting.local_schemes.boolean" title="Permalink to this headline">¶</a></h3>
<p>A simple local term-weighting scheme that sets the weight of a term to 1 if it appears in the document.
The weight <span class="math notranslate nohighlight">\(bool_{t,d}\)</span> of a feature <span class="math notranslate nohighlight">\(t\)</span> is simply 1 if it appears in a document <span class="math notranslate nohighlight">\(d\)</span>, 0 otherwise.</p>
<div class="math notranslate nohighlight">
\[\begin{split}bool_{t,d} = \begin{cases}
                             1 &amp; \text{if } t \in d \\
                                 0 &amp; \text{otherwise}
                         \end{cases}\end{split}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.local_schemes.boolean.Boolean">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.local_schemes.boolean.</code><code class="sig-name descname">Boolean</code><a class="headerlink" href="#nlp.term_weighting.local_schemes.boolean.Boolean" title="Permalink to this definition">¶</a></dt>
<dd><p>The boolean term-weighting scheme is one of the simplest term weighting schemes that is used.
The weight of a feature is 1 if it appears in a document, 0 otherwise.</p>
<dl class="method">
<dt id="nlp.term_weighting.local_schemes.boolean.Boolean.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.local_schemes.boolean.Boolean.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.
The score is 1 if a feature appears in the document, 0 otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.term_weighting.local_schemes.tf"></span><p>The Term Frequency (TF) local term-weighting scheme assigns a weight to each term according to the number of times that it appears.
The term frequency <span class="math notranslate nohighlight">\(tf_{t,d}\)</span> of a feature <span class="math notranslate nohighlight">\(t\)</span> is equivalent to its frequency <span class="math notranslate nohighlight">\(f_{t,d}\)</span> in document <span class="math notranslate nohighlight">\(d\)</span>:</p>
<div class="math notranslate nohighlight">
\[tf_{t,d} = f_{t,d}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.local_schemes.tf.TF">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.local_schemes.tf.</code><code class="sig-name descname">TF</code><a class="headerlink" href="#nlp.term_weighting.local_schemes.tf.TF" title="Permalink to this definition">¶</a></dt>
<dd><p>The Term Frequency (TF) term-weighting scheme is one of the simplest term weighting schemes that is used.
The weight of a dimension is simply the number of times that the feature appears.</p>
<dl class="method">
<dt id="nlp.term_weighting.local_schemes.tf.TF.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.local_schemes.tf.TF.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.
The score is equal to the frequency of the token in the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.term_weighting.global_schemes.filler">
<span id="global-term-weighting-schemes"></span><h3>Global Term-Weighting Schemes<a class="headerlink" href="#module-nlp.term_weighting.global_schemes.filler" title="Permalink to this headline">¶</a></h3>
<p>The filler global term-weighting scheme is used when there is no need for a global term-weighting scheme.
The scheme assigns the same score <span class="math notranslate nohighlight">\(fill_{t,d}\)</span> to all terms <span class="math notranslate nohighlight">\(t\)</span> if they appear in the document <span class="math notranslate nohighlight">\(d\)</span>, 0 otherwise:</p>
<div class="math notranslate nohighlight">
\[\begin{split}fill_{t,d} = \begin{cases}
                             1 &amp; \text{if } t \in d \\
                                 0 &amp; \text{otherwise}
                         \end{cases}\end{split}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.global_schemes.filler.Filler">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.global_schemes.filler.</code><code class="sig-name descname">Filler</code><a class="headerlink" href="#nlp.term_weighting.global_schemes.filler.Filler" title="Permalink to this definition">¶</a></dt>
<dd><p>The filler global term-weighting scheme is used when there is no need for a global term-weighting scheme.
The scheme assigns the same score to all terms: 1.</p>
<dl class="method">
<dt id="nlp.term_weighting.global_schemes.filler.Filler.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.filler.Filler.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.term_weighting.global_schemes.idf"></span><p>The Inverse Document Frequency (IDF) global term-weighting scheme penalizes common terms.
The reasoning is that common terms are not informative.
Terms that appear often in one document but rarely outside characterize that document.</p>
<p>The IDF <span class="math notranslate nohighlight">\(idf_{t}\)</span> for term <span class="math notranslate nohighlight">\(t\)</span> is computed as follows:</p>
<div class="math notranslate nohighlight">
\[idf_{t} = \log{\frac{N}{n_t}}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the total number of documents and <span class="math notranslate nohighlight">\(n_t\)</span> is the total number of documents in <span class="math notranslate nohighlight">\(N\)</span> that contain term <span class="math notranslate nohighlight">\(t\)</span>.</p>
<dl class="class">
<dt id="nlp.term_weighting.global_schemes.idf.IDF">
<em class="property">class </em><code class="sig-prename descclassname">nlp.term_weighting.global_schemes.idf.</code><code class="sig-name descname">IDF</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF" title="Permalink to this definition">¶</a></dt>
<dd><p>The Inverse Document Frequency (TF-IDF) is one of the most common term-weighting schemes.
This scheme promotes uncommon tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><p><a class="reference internal" href="#module-nlp.term_weighting.global_schemes.idf" title="nlp.term_weighting.global_schemes.idf"><strong>idf</strong></a> (<em>dict</em>) – The IDF table used in conjunction with term weighting.</p>
</dd>
</dl>
<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the term-weighting scheme with the IDF table and the number of documents in that scheme.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idf</strong> (<em>dict</em>) – The IDF table used in conjunction with term weighting.
The keys are the terms, and the corresponding values are the number of documents in which they appear.</p></li>
<li><p><strong>documents</strong> (<em>int</em>) – The number of documents in the IDF table.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – When the document frequency of a term is higher than the number of the IDF documents.</p></li>
<li><p><strong>ValueError</strong> – When the document frequency of a term is negative.</p></li>
<li><p><strong>ValueError</strong> – When the number of documents is negative.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.from_documents">
<em class="property">static </em><code class="sig-name descname">from_documents</code><span class="sig-paren">(</span><em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.from_documents" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the IDF table from the given set of documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>documents</strong> (list of <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">nlp.document.Document</span></code></a>) – The documents from which the IDF table will be created.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary, where the keys are the document tokens and the values are their document frequency.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="apd.html" class="btn btn-neutral float-right" title="4. Automatic Participant Detection (APD)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="vsm.html" class="btn btn-neutral float-left" title="2. Vector Space Model (VSM)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Nicholas Mamo

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>