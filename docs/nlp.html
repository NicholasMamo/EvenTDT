

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="The Natural Language Processing (NLP) library" name="description" />
<meta content="Python, TDT, NLP" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3. Natural Language Processing (NLP) &mdash; EvenTDT 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Wikinterface" href="wikinterface.html" />
    <link rel="prev" title="2. Vector Space Model (VSM)" href="vsm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> EvenTDT
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="config.html">0. Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">1. Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="vsm.html">2. Vector Space Model (VSM)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. Natural Language Processing (NLP)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-nlp.document">Documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-nlp.tokenizer">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-nlp.term_weighting">Term-Weighting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp.term_weighting.tf">Common Term-Weighting Schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp.term_weighting.local_schemes.boolean">Local Term-Weighting Schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nlp.term_weighting.global_schemes.filler">Global Term-Weighting Schemes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cleaners">Cleaners</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="wikinterface.html">4. Wikinterface</a></li>
<li class="toctree-l1"><a class="reference internal" href="apd.html">5. Automatic Participant Detection (APD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tdt.html">6. Topic Detection and Tracking (TDT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="summarization.html">7. Summarization</a></li>
<li class="toctree-l1"><a class="reference internal" href="twitter.html">8. Twitter</a></li>
<li class="toctree-l1"><a class="reference internal" href="consumers.html">9. Consumers</a></li>
<li class="toctree-l1"><a class="reference internal" href="other.html">10. Other</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">EvenTDT</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>3. Natural Language Processing (NLP)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/nlp.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="natural-language-processing-nlp">
<h1>3. Natural Language Processing (NLP)<a class="headerlink" href="#natural-language-processing-nlp" title="Permalink to this headline">¶</a></h1>
<p>Documents find their basis in the Vector Space Model (VSM).
For this reason, EvenTDT’s documents are based on the <code class="xref py py-class docutils literal notranslate"><span class="pre">Vector</span></code> class.
EvenTDT adds functionality to make it easier to work with documents, including by storing the original text.
Keep reading to learn more about the different NLP classes available in EvenTDT.</p>
<span class="target" id="module-nlp"></span><div class="section" id="module-nlp.document">
<span id="documents"></span><h2>Documents<a class="headerlink" href="#module-nlp.document" title="Permalink to this headline">¶</a></h2>
<p>Documents are the basis in NLP tasks.
The <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a> class builds on the <a class="reference internal" href="vsm.html#vsm.vector.Vector" title="vsm.vector.Vector"><code class="xref py py-class docutils literal notranslate"><span class="pre">Vector</span></code></a> class.
In addition to the normal VSM functionality, it stores the original text for any later changes.</p>
<p>Creating documents is a two-step process.
First, the text needs to be converted into tokens using the <a class="reference internal" href="#nlp.tokenizer.Tokenizer" title="nlp.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tokenizer</span></code></a> class.
Second, those tokens need to be weighted using a <a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a>, transforming them into document features, or vector dimensions.</p>
<dl class="class">
<dt id="nlp.document.Document">
<em class="property">class </em><code class="sig-name descname">Document</code><span class="sig-paren">(</span><em class="sig-param">text=''</em>, <em class="sig-param">dimensions=None</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a> class is based on the <a class="reference internal" href="vsm.html#vsm.vector.Vector" title="vsm.vector.Vector"><code class="xref py py-class docutils literal notranslate"><span class="pre">Vector</span></code></a> class. class.
The main addition is the text field for any later changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><p><a class="reference internal" href="wikinterface.html#module-wikinterface.text" title="wikinterface.text"><strong>text</strong></a> (<em>str</em>) – The document’s original text.</p>
</dd>
</dl>
<dl class="method">
<dt id="nlp.document.Document.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">text=''</em>, <em class="sig-param">dimensions=None</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the document with the text and optional dimensions.
Any other arguments or keyword arguments are passed on to the <a class="reference internal" href="vsm.html#vsm.vector.Vector" title="vsm.vector.Vector"><code class="xref py py-class docutils literal notranslate"><span class="pre">Vector</span></code></a> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<em>str</em>) – The document’s text.</p></li>
<li><p><strong>dimensions</strong> (<em>list</em><em> or </em><em>dict</em>) – The initial dimensions of the document.
If a list is provided, it is assumed that they are tokens.
The dimensions are then created from this list using the given scheme.</p></li>
<li><p><strong>scheme</strong> (None or <code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeighting</span></code>) – The term-weighting scheme that is used to convert the tokens into dimensions.
If <cite>None</cite> is given, the <code class="xref py py-class docutils literal notranslate"><span class="pre">TF</span></code> term-weighting scheme is used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.__str__">
<code class="sig-name descname">__str__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.__str__" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the string representation of the document.
This is equivalent to the document’s text.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The text of the document.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of the document.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A copy of the <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.to_array">
<code class="sig-name descname">to_array</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.to_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Export the document as an associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The document as an associative array.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.from_array">
<em class="property">static </em><code class="sig-name descname">from_array</code><span class="sig-paren">(</span><em class="sig-param">array</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.from_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the document from the given associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>array</strong> (<em>dict</em>) – The associative array with the attributes to create the document.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of an object with the same attributes stored in the object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.document.Document.concatenate">
<em class="property">static </em><code class="sig-name descname">concatenate</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">tokenizer</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.document.Document.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenate all of the documents that are provided as arguments.
The function first concatenates the text of all the documents.
Then, it tokenizes the concatenated and creates a document from it.</p>
<p>Any additional keyword arguments are passed on to the Document constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheme</strong> (<a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a>) – The term-weighting scheme to use to create the concatenated document.</p></li>
<li><p><strong>tokenizer</strong> (<a class="reference internal" href="#nlp.tokenizer.Tokenizer" title="nlp.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tokenizer</span></code></a>) – The tokenizer to use to construct the concatenated document.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new document representing the concatenated documents.
The document is not normalized.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.tokenizer">
<span id="tokenization"></span><h2>Tokenization<a class="headerlink" href="#module-nlp.tokenizer" title="Permalink to this headline">¶</a></h2>
<p>The tokenizer takes plain text and splits it into a list of tokens.
Tokens are the equivalent of document features, or vector dimensions.</p>
<p>Tokenization is the first of two steps to create a <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a>.
The second step is term-weighting using a <a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a>.
A term-weighting scheme receives tokens and creates a weighted <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a> out of them.</p>
<p>The tokenizer takes its settings in the constructor.
All tokenization happens using the <a class="reference internal" href="#nlp.tokenizer.Tokenizer.tokenize" title="nlp.tokenizer.Tokenizer.tokenize"><code class="xref py py-func docutils literal notranslate"><span class="pre">tokenize()</span></code></a> function.
In this way, all documents are tokenized in the same way.
Creating and using a tokenizer is very simple:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">stem</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">split_hashtags</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">tokenize</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Stemming is based on, and requires, NLTK.</p>
</div>
<dl class="class">
<dt id="nlp.tokenizer.Tokenizer">
<em class="property">class </em><code class="sig-name descname">Tokenizer</code><span class="sig-paren">(</span><em class="sig-param">remove_mentions=True</em>, <em class="sig-param">remove_hashtags=False</em>, <em class="sig-param">split_hashtags=True</em>, <em class="sig-param">remove_numbers=True</em>, <em class="sig-param">remove_urls=True</em>, <em class="sig-param">remove_alt_codes=True</em>, <em class="sig-param">normalize_words=False</em>, <em class="sig-param">character_normalization_count=3</em>, <em class="sig-param">case_fold=True</em>, <em class="sig-param">remove_punctuation=True</em>, <em class="sig-param">remove_unicode_entities=False</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">stopwords=None</em>, <em class="sig-param">stem=True</em>, <em class="sig-param">normalize_special_characters=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>The tokenizer takes in strings and converts them into tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stemmer</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">PorterStemmer</span></code>) – The Porter Stemmer used by the class.</p></li>
<li><p><strong>remove_mentions</strong> (<em>bool</em>) – A boolean indicating whether mentions (&#64;) should be removed.</p></li>
<li><p><strong>remove_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be removed.</p></li>
<li><p><strong>split_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be normalized.
This converts hashtags of the type #HashTag to <cite>Hash Tag</cite>, based on camel-case.</p></li>
<li><p><strong>remove_numbers</strong> (<em>bool</em>) – A boolean indicating whether numbers should be removed.</p></li>
<li><p><strong>remove_urls</strong> (<em>bool</em>) – A boolean indicating whether URLs should be removed.</p></li>
<li><p><strong>remove_alt_codes</strong> (<em>bool</em>) – A boolean indicating whether ALT-codes should be removed.</p></li>
<li><p><strong>normalize_words</strong> (<em>bool</em>) – A boolean indicating whether words should be normalized.
This removes repeated characters.
The number of repeated characters that are removed is controlled using the <cite>character_normalization_count</cite> parameter.</p></li>
<li><p><strong>character_normalization_count</strong> (<em>int</em>) – The number of times a character is repeated before they are reduced to one.</p></li>
<li><p><strong>case_fold</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be case-folded to lowercase.</p></li>
<li><p><strong>remove_punctuation</strong> (<em>bool</em>) – A boolean indicating whether punctuation should be removed.</p></li>
<li><p><strong>remove_unicode_entities</strong> (<em>bool</em>) – A boolean indicating whether unicode entities should be removed.</p></li>
<li><p><strong>min_length</strong> (<em>int</em>) – The minimum length of tokens that should be retained.</p></li>
<li><p><strong>stopwords</strong> (<em>list</em>) – A list of stopwords.
Stopwords are common words that are removed from token lists.
This is based on the assumption that they are not very expressive.
Normally, stopwords are provided as a list, and then converted into a dict, where the stopwords are the keys.
This approach is adopted since Python uses hashing to check whether a key is in a dict.
However, they may also be provided as a dict directly.</p></li>
<li><p><strong>stem</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be stemmed.</p></li>
<li><p><strong>normalize_special_characters</strong> (<em>bool</em>) – A boolean indicating whether accents should be removed and replaced with simple unicode characters.</p></li>
<li><p><a class="reference internal" href="#nlp.tokenizer.Tokenizer.stem_cache" title="nlp.tokenizer.Tokenizer.stem_cache"><strong>stem_cache</strong></a> (<em>dict</em>) – A mapping of tokens and their stems.
The keys are the original tokens and the values are their stems.</p></li>
<li><p><strong>url_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify URLs in the text.</p></li>
<li><p><strong>alt_code_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify and remove alt-codes from the text.</p></li>
<li><p><strong>mention_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify mentions in the text.</p></li>
<li><p><strong>hashtag_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify hashtags in the text.</p></li>
<li><p><strong>word_normalization_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify words with repeated characters.</p></li>
<li><p><strong>number_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify numbers in the text.</p></li>
<li><p><strong>tokenize_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to split the text into tokens.</p></li>
<li><p><strong>camel_case_pattern</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">re.Pattern</span></code>) – The pattern used to identify camel-case letters.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nlp.tokenizer.Tokenizer.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">remove_mentions=True</em>, <em class="sig-param">remove_hashtags=False</em>, <em class="sig-param">split_hashtags=True</em>, <em class="sig-param">remove_numbers=True</em>, <em class="sig-param">remove_urls=True</em>, <em class="sig-param">remove_alt_codes=True</em>, <em class="sig-param">normalize_words=False</em>, <em class="sig-param">character_normalization_count=3</em>, <em class="sig-param">case_fold=True</em>, <em class="sig-param">remove_punctuation=True</em>, <em class="sig-param">remove_unicode_entities=False</em>, <em class="sig-param">min_length=3</em>, <em class="sig-param">stopwords=None</em>, <em class="sig-param">stem=True</em>, <em class="sig-param">normalize_special_characters=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the tokenizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>remove_mentions</strong> (<em>bool</em>) – A boolean indicating whether mentions (&#64;) should be removed.</p></li>
<li><p><strong>remove_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be removed.</p></li>
<li><p><strong>split_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags (#) should be normalized.
This converts hashtags of the type #HashTag to <cite>Hash Tag</cite>, based on camel-case.</p></li>
<li><p><strong>remove_numbers</strong> (<em>bool</em>) – A boolean indicating whether numbers should be removed.</p></li>
<li><p><strong>remove_urls</strong> (<em>bool</em>) – A boolean indicating whether URLs should be removed.</p></li>
<li><p><strong>remove_alt_codes</strong> (<em>bool</em>) – A boolean indicating whether ALT-codes should be removed.</p></li>
<li><p><strong>normalize_words</strong> (<em>bool</em>) – A boolean indicating whether words should be normalized.
This removes repeated characters.
The number of repeated characters that are removed is controlled using the <cite>character_normalization_count</cite> parameter.</p></li>
<li><p><strong>character_normalization_count</strong> (<em>int</em>) – The number of times a character is repeated before they are reduced to one.</p></li>
<li><p><strong>case_fold</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be case-folded to lowercase.</p></li>
<li><p><strong>remove_punctuation</strong> (<em>bool</em>) – A boolean indicating whether punctuation should be removed.</p></li>
<li><p><strong>remove_unicode_entities</strong> (<em>bool</em>) – A boolean indicating whether unicode entities should be removed.
Note that this also includes emojis.</p></li>
<li><p><strong>min_length</strong> (<em>int</em>) – The minimum length of tokens that should be retained.</p></li>
<li><p><strong>stopwords</strong> (<em>list</em>) – A list of stopwords: common words that are removed from token lists.
This is based on the assumption that they are not very expressive.
Normally, stopwords are provided as a list, and then converted into a dict, where the stopwords are the keys.
This approach is adopted since Python uses hashing to check whether a key is in a dict.
However, they may also be provided as a dict directly.</p></li>
<li><p><strong>stem</strong> (<em>bool</em>) – A boolean indicating whether the tokens should be stemmed.</p></li>
<li><p><strong>normalize_special_characters</strong> (<em>bool</em>) – A boolean indicating whether accents should be removed and replaced with simple unicode characters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.tokenizer.Tokenizer.stem_cache">
<code class="sig-name descname">stem_cache</code><em class="property"> = None</em><a class="headerlink" href="#nlp.tokenizer.Tokenizer.stem_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>The list of regular expressions to be used.</p>
</dd></dl>

<dl class="method">
<dt id="nlp.tokenizer.Tokenizer.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize the given text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to tokenize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of tokens.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.tokenizer.Tokenizer._split_hashtags">
<code class="sig-name descname">_split_hashtags</code><span class="sig-paren">(</span><em class="sig-param">string</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer._split_hashtags" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the hashtags in the given string based on camel-case notation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>string</strong> (<em>str</em>) – The string to normalize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The normalized string.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.tokenizer.Tokenizer.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.tokenizer.Tokenizer.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

<dl class="method">
<dt id="nlp.tokenizer.Tokenizer._stem">
<code class="sig-name descname">_stem</code><span class="sig-paren">(</span><em class="sig-param">tokens</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.tokenizer.Tokenizer._stem" title="Permalink to this definition">¶</a></dt>
<dd><p>Stem the given tokens.
Stemming is an expensive operation.
Therefore the function uses a stem cache to avoid re-stemming previously-seen tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The tokens to stem.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of stemmed tokens.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.term_weighting">
<span id="term-weighting"></span><h2>Term-Weighting<a class="headerlink" href="#module-nlp.term_weighting" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-nlp.term_weighting.scheme"></span><p>Term-weighting schemes give different weights to different terms in a document.
Traditionally, term-weighting schemes have at least a local and global component.</p>
<dl class="class">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme">
<em class="property">class </em><code class="sig-name descname">TermWeightingScheme</code><span class="sig-paren">(</span><em class="sig-param">local_scheme</em>, <em class="sig-param">global_scheme</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="Permalink to this definition">¶</a></dt>
<dd><p>This class defines a list of properties that all term-weighting schemes must have.
The class can be instantiated by providing a local term-weighting scheme and a global term-weighting scheme.
The scheme then multiplies the scores of each to <a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme.create" title="nlp.term_weighting.scheme.TermWeightingScheme.create"><code class="xref py py-func docutils literal notranslate"><span class="pre">create()</span></code></a> a <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Scheme</span></code>) – The local term-weighting scheme.</p></li>
<li><p><strong>global_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Scheme</span></code>) – The global term-weighting scheme.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">local_scheme</em>, <em class="sig-param">global_scheme</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>A term-weighting scheme is made up of a local component and a global component.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Scheme</span></code>) – The local term-weighting scheme.</p></li>
<li><p><strong>global_scheme</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Scheme</span></code>) – The global term-weighting scheme.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme.create">
<code class="sig-name descname">create</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme.create" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a document from the given tokens.
The function multiplies the local and global scores of each token.
The function accepts other arguments or keyword arguments, such as the document text or attributes.
These are passed on to the <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – A list of tokens that can be converted into dimensions.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new document with the given tokens as the dimensions.
The dimensions’ weights depend on the term-weighting scheme.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.term_weighting.scheme.TermWeightingScheme.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.term_weighting.scheme.TermWeightingScheme.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nlp.term_weighting.scheme.SchemeScorer">
<em class="property">class </em><code class="sig-name descname">SchemeScorer</code><a class="headerlink" href="#nlp.term_weighting.scheme.SchemeScorer" title="Permalink to this definition">¶</a></dt>
<dd><p>A scheme is used to score documents’ tokens.
It is important to distinguish between <a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a> and <a class="reference internal" href="#nlp.term_weighting.scheme.SchemeScorer" title="nlp.term_weighting.scheme.SchemeScorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">SchemeScorer</span></code></a>.
The former is a complete term-weighting scheme that takes local and global scheme scorers.
The latter is the actual scorer.
A <a class="reference internal" href="#nlp.term_weighting.scheme.SchemeScorer" title="nlp.term_weighting.scheme.SchemeScorer"><code class="xref py py-class docutils literal notranslate"><span class="pre">SchemeScorer</span></code></a> is a component of a term-weighting scheme.
A <a class="reference internal" href="#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a> combines local and global scorers to create documents.</p>
<dl class="method">
<dt id="nlp.term_weighting.scheme.SchemeScorer.score">
<em class="property">abstract </em><code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.scheme.SchemeScorer.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given list of tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.term_weighting.scheme.SchemeScorer.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.term_weighting.scheme.SchemeScorer.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<div class="section" id="module-nlp.term_weighting.tf">
<span id="common-term-weighting-schemes"></span><h3>Common Term-Weighting Schemes<a class="headerlink" href="#module-nlp.term_weighting.tf" title="Permalink to this headline">¶</a></h3>
<p>The term frequency term-weighting scheme is used when there is no need for a global scheme.
The term frequency <span class="math notranslate nohighlight">\(tf_{t,d}\)</span> of a feature <span class="math notranslate nohighlight">\(t\)</span> is equivalent to its frequency <span class="math notranslate nohighlight">\(f_{t,d}\)</span> in document <span class="math notranslate nohighlight">\(d\)</span>:</p>
<div class="math notranslate nohighlight">
\[tf_{t,d} = f_{t,d}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.tf.TF">
<em class="property">class </em><code class="sig-name descname">TF</code><a class="headerlink" href="#nlp.term_weighting.tf.TF" title="Permalink to this definition">¶</a></dt>
<dd><p>The TF scheme is used when there is no need for a global scheme.</p>
<dl class="method">
<dt id="nlp.term_weighting.tf.TF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tf.TF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the TF-IDF term-weighting scheme by supplying the TF and filler schemes.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.term_weighting.tfidf"></span><p>The Term Frequency-Inverse Document Frequency (TF-IDF) term-weighting scheme is one of the most popular schemes.
The scheme promotes features that appear commonly in a document, but rarely outside of it.
The TFIDF is simply the multiplication of the <a class="reference internal" href="#nlp.term_weighting.local_schemes.tf.TF" title="nlp.term_weighting.local_schemes.tf.TF"><code class="xref py py-class docutils literal notranslate"><span class="pre">TF</span></code></a> and <a class="reference internal" href="#nlp.term_weighting.global_schemes.idf.IDF" title="nlp.term_weighting.global_schemes.idf.IDF"><code class="xref py py-class docutils literal notranslate"><span class="pre">IDF</span></code></a> term-weighting schemes:
The weight <span class="math notranslate nohighlight">\(tfidf_{t,d}\)</span> of term <span class="math notranslate nohighlight">\(idf_{t}\)</span> in document <span class="math notranslate nohighlight">\(d\)</span> is computed as follows:</p>
<div class="math notranslate nohighlight">
\[tfidf_{t,d} = tf_{t,d} \cdot idf_{t}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.tfidf.TFIDF">
<em class="property">class </em><code class="sig-name descname">TFIDF</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tfidf.TFIDF" title="Permalink to this definition">¶</a></dt>
<dd><p>The Term Frequency-Inverse Document Frequency (TF-IDF) term-weighting scheme is one of the most popular schemes.
The scheme promotes features that appear commonly in a document, but rarely outside of it.</p>
<dl class="method">
<dt id="nlp.term_weighting.tfidf.TFIDF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tfidf.TFIDF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the TF-IDF term-weighting scheme by supplying the TF and IDF schemes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idf</strong> (<em>dict</em>) – The IDF table used in conjunction with term weighting.
The keys are the terms, and the corresponding values are the number of documents in which they appear.</p></li>
<li><p><strong>documents</strong> (<em>int</em>) – The number of documents in the IDF table.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.tfidf.TFIDF.to_array">
<code class="sig-name descname">to_array</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tfidf.TFIDF.to_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Export the TF-IDF as an associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The TF-IDF as an associative array.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.tfidf.TFIDF.from_array">
<em class="property">static </em><code class="sig-name descname">from_array</code><span class="sig-paren">(</span><em class="sig-param">array</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.tfidf.TFIDF.from_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the TF-IDF from the given associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>array</strong> (<em>dict</em>) – The associative array with the attributes to create the TF-IDF.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of the TF-IDF with the same attributes stored in the object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nlp.term_weighting.tfidf.TFIDF" title="nlp.term_weighting.tfidf.TFIDF"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFIDF</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.term_weighting.local_schemes.boolean">
<span id="local-term-weighting-schemes"></span><h3>Local Term-Weighting Schemes<a class="headerlink" href="#module-nlp.term_weighting.local_schemes.boolean" title="Permalink to this headline">¶</a></h3>
<p>A simple local term-weighting scheme that sets the weight of a term to 1 if it appears in the document.
The weight <span class="math notranslate nohighlight">\(bool_{t,d}\)</span> of a feature <span class="math notranslate nohighlight">\(t\)</span> is simply 1 if it appears in a document <span class="math notranslate nohighlight">\(d\)</span>, 0 otherwise.</p>
<div class="math notranslate nohighlight">
\[\begin{split}bool_{t,d} = \begin{cases}
                             1 &amp; \text{if } t \in d \\
                                 0 &amp; \text{otherwise}
                         \end{cases}\end{split}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.local_schemes.boolean.Boolean">
<em class="property">class </em><code class="sig-name descname">Boolean</code><a class="headerlink" href="#nlp.term_weighting.local_schemes.boolean.Boolean" title="Permalink to this definition">¶</a></dt>
<dd><p>The boolean term-weighting scheme is one of the simplest term weighting schemes that is used.
The weight of a feature is 1 if it appears in a document, 0 otherwise.</p>
<dl class="method">
<dt id="nlp.term_weighting.local_schemes.boolean.Boolean.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.local_schemes.boolean.Boolean.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.
The score is 1 if a feature appears in the document, 0 otherwise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.term_weighting.local_schemes.tf"></span><p>The Term Frequency (TF) local term-weighting scheme assigns a weight to each term according to the number of times that it appears.
The term frequency <span class="math notranslate nohighlight">\(tf_{t,d}\)</span> of a feature <span class="math notranslate nohighlight">\(t\)</span> is equivalent to its frequency <span class="math notranslate nohighlight">\(f_{t,d}\)</span> in document <span class="math notranslate nohighlight">\(d\)</span>:</p>
<div class="math notranslate nohighlight">
\[tf_{t,d} = f_{t,d}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.local_schemes.tf.TF">
<em class="property">class </em><code class="sig-name descname">TF</code><a class="headerlink" href="#nlp.term_weighting.local_schemes.tf.TF" title="Permalink to this definition">¶</a></dt>
<dd><p>The Term Frequency (TF) term-weighting scheme is one of the simplest term weighting schemes that is used.
The weight of a dimension is simply the number of times that the feature appears.</p>
<dl class="method">
<dt id="nlp.term_weighting.local_schemes.tf.TF.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.local_schemes.tf.TF.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.
The score is equal to the frequency of the token in the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nlp.term_weighting.global_schemes.filler">
<span id="global-term-weighting-schemes"></span><h3>Global Term-Weighting Schemes<a class="headerlink" href="#module-nlp.term_weighting.global_schemes.filler" title="Permalink to this headline">¶</a></h3>
<p>The filler global term-weighting scheme is used when there is no need for a global term-weighting scheme.
The scheme assigns the same score <span class="math notranslate nohighlight">\(fill_{t,d}\)</span> to all terms <span class="math notranslate nohighlight">\(t\)</span> if they appear in the document <span class="math notranslate nohighlight">\(d\)</span>, 0 otherwise:</p>
<div class="math notranslate nohighlight">
\[\begin{split}fill_{t,d} = \begin{cases}
                             1 &amp; \text{if } t \in d \\
                                 0 &amp; \text{otherwise}
                         \end{cases}\end{split}\]</div>
<dl class="class">
<dt id="nlp.term_weighting.global_schemes.filler.Filler">
<em class="property">class </em><code class="sig-name descname">Filler</code><a class="headerlink" href="#nlp.term_weighting.global_schemes.filler.Filler" title="Permalink to this definition">¶</a></dt>
<dd><p>The filler global term-weighting scheme is used when there is no need for a global term-weighting scheme.
The scheme assigns the same score to all terms: 1.</p>
<dl class="method">
<dt id="nlp.term_weighting.global_schemes.filler.Filler.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.filler.Filler.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.term_weighting.global_schemes.idf"></span><p>The Inverse Document Frequency (IDF) global term-weighting scheme penalizes common terms.
The reasoning is that common terms are not informative.
Terms that appear often in one document but rarely outside characterize that document.</p>
<p>The IDF <span class="math notranslate nohighlight">\(idf_{t}\)</span> for term <span class="math notranslate nohighlight">\(t\)</span> is computed as follows:</p>
<div class="math notranslate nohighlight">
\[idf_{t} = \log{\frac{N}{n_t}}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the total number of documents and <span class="math notranslate nohighlight">\(n_t\)</span> is the total number of documents in <span class="math notranslate nohighlight">\(N\)</span> that contain term <span class="math notranslate nohighlight">\(t\)</span>.</p>
<dl class="class">
<dt id="nlp.term_weighting.global_schemes.idf.IDF">
<em class="property">class </em><code class="sig-name descname">IDF</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF" title="Permalink to this definition">¶</a></dt>
<dd><p>The Inverse Document Frequency (TF-IDF) is one of the most common term-weighting schemes.
This scheme promotes uncommon tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><p><a class="reference internal" href="#module-nlp.term_weighting.global_schemes.idf" title="nlp.term_weighting.global_schemes.idf"><strong>idf</strong></a> (<em>dict</em>) – The IDF table used in conjunction with term weighting.</p>
</dd>
</dl>
<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the term-weighting scheme with the IDF table and the number of documents in that scheme.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idf</strong> (<em>dict</em>) – The IDF table used in conjunction with term weighting.
The keys are the terms, and the corresponding values are the number of documents in which they appear.</p></li>
<li><p><strong>documents</strong> (<em>int</em>) – The number of documents in the IDF table.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – When the document frequency of a term is higher than the number of the IDF documents.</p></li>
<li><p><strong>ValueError</strong> – When the document frequency of a term is negative.</p></li>
<li><p><strong>ValueError</strong> – When the number of documents is negative.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">tokens</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the given tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tokens</strong> (<em>list of str</em>) – The list of tokens to weigh.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary with the tokens as the keys and the weights as the values.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.to_array">
<code class="sig-name descname">to_array</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.to_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Export the IDF as an associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The IDF as an associative array.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.from_array">
<em class="property">static </em><code class="sig-name descname">from_array</code><span class="sig-paren">(</span><em class="sig-param">array</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.from_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the IDF from the given associative array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>array</strong> (<em>dict</em>) – The associative array with the attributes to create the IDF.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new instance of the IDF with the same attributes stored in the object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nlp.term_weighting.global_schemes.idf.IDF" title="nlp.term_weighting.global_schemes.idf.IDF"><code class="xref py py-class docutils literal notranslate"><span class="pre">IDF</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.term_weighting.global_schemes.idf.IDF.from_documents">
<em class="property">static </em><code class="sig-name descname">from_documents</code><span class="sig-paren">(</span><em class="sig-param">documents</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.term_weighting.global_schemes.idf.IDF.from_documents" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the IDF table from the given set of documents.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>documents</strong> (list of <a class="reference internal" href="#nlp.document.Document" title="nlp.document.Document"><code class="xref py py-class docutils literal notranslate"><span class="pre">Document</span></code></a>) – The documents from which the IDF table will be created.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary, where the keys are the document tokens and the values are their document frequency.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="cleaners">
<h2>Cleaners<a class="headerlink" href="#cleaners" title="Permalink to this headline">¶</a></h2>
<p>EvenTDT comes with classes to clean documents.
These can be used, for example, to clean summaries.</p>
<span class="target" id="module-nlp.cleaners.cleaner"></span><p>A cleaner takes in strings and cleans them according to some rules.
Any configuration is passed on to the constructor, <a class="reference internal" href="#nlp.cleaners.cleaner.Cleaner.__init__" title="nlp.cleaners.cleaner.Cleaner.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a>.
Without any configuration, the cleaner should change nothing.
Then, the cleaners’ main functionality revolves around the <a class="reference internal" href="#nlp.cleaners.cleaner.Cleaner.clean" title="nlp.cleaners.cleaner.Cleaner.clean"><code class="xref py py-func docutils literal notranslate"><span class="pre">clean()</span></code></a> function.</p>
<dl class="class">
<dt id="nlp.cleaners.cleaner.Cleaner">
<em class="property">class </em><code class="sig-name descname">Cleaner</code><span class="sig-paren">(</span><em class="sig-param">remove_alt_codes=False</em>, <em class="sig-param">complete_sentences=False</em>, <em class="sig-param">collapse_new_lines=False</em>, <em class="sig-param">collapse_whitespaces=False</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner" title="Permalink to this definition">¶</a></dt>
<dd><p>The base cleaner is meant to perform only basing pre-processing and cleaning.
These functions are generally applicable to any type of text.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>remove_alt_codes</strong> (<em>bool</em>) – A boolean indicating whether alt-codes should be removed.</p></li>
<li><p><strong>complete_sentences</strong> (<em>bool</em>) – A boolean indicating whether the sentences should be completed.
The cleaner has no knowledge of any incomplete sentences in the middle of the text.
Therefore it only completes the last sentence.</p></li>
<li><p><strong>collapse_new_lines</strong> (<em>bool</em>) – A boolean indicating whether new lines should be collapsed into whitespaces.</p></li>
<li><p><strong>collapse_whitespaces</strong> (<em>bool</em>) – A boolean indicating whether consecutive whitespaces and tabs should be collapsed into a single whitespace.
This also removes whitespaces just before periods.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nlp.cleaners.cleaner.Cleaner.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">remove_alt_codes=False</em>, <em class="sig-param">complete_sentences=False</em>, <em class="sig-param">collapse_new_lines=False</em>, <em class="sig-param">collapse_whitespaces=False</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the cleaner with the basic configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>remove_alt_codes</strong> (<em>bool</em>) – A boolean indicating whether alt-codes should be removed.</p></li>
<li><p><strong>complete_sentences</strong> (<em>bool</em>) – A boolean indicating whether the sentences should be completed.
The cleaner has no knowledge of any incomplete sentences in the middle of the text.
Therefore it only completes the last sentence.</p></li>
<li><p><strong>collapse_new_lines</strong> (<em>bool</em>) – A boolean indicating whether new lines should be collapsed into whitespaces.</p></li>
<li><p><strong>collapse_whitespaces</strong> (<em>bool</em>) – A boolean indicating whether consecutive whitespaces and tabs should be collapsed into a single whitespace.
This also removes whitespaces just before periods.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.cleaner.Cleaner.clean">
<code class="sig-name descname">clean</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner.clean" title="Permalink to this definition">¶</a></dt>
<dd><p>Clean the given text.
The basic cleaner always strips empty whitespaces before and after all processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The cleaned text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.cleaner.Cleaner._collapse_new_lines">
<code class="sig-name descname">_collapse_new_lines</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner._collapse_new_lines" title="Permalink to this definition">¶</a></dt>
<dd><p>Collapse new lines into white spaces.</p>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.cleaner.Cleaner._remove_alt_codes">
<code class="sig-name descname">_remove_alt_codes</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner._remove_alt_codes" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove alt-codes from the given text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The text without alt-codes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.cleaner.Cleaner._complete_sentences">
<code class="sig-name descname">_complete_sentences</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner._complete_sentences" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a period if the sentence does not end with punctuation.
There is one exception to this rule: if the sentence ends with a quote.
In this case, the period is added before the quote if there is no punctuation there..</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The text without alt-codes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.cleaner.Cleaner._collapse_whitespaces">
<code class="sig-name descname">_collapse_whitespaces</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner._collapse_whitespaces" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove consecutive whitespaces and tabs, and replace them with a single space.
This also removes whitespaces just before periods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The text without any consectuive spaces or tabs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="nlp.cleaners.cleaner.Cleaner.__weakref__">
<code class="sig-name descname">__weakref__</code><a class="headerlink" href="#nlp.cleaners.cleaner.Cleaner.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-nlp.cleaners.tweet_cleaner"></span><p>The tweet cleaner builds on the base cleaner, but adds Twitter-specific functionality.</p>
<dl class="class">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner">
<em class="property">class </em><code class="sig-name descname">TweetCleaner</code><span class="sig-paren">(</span><em class="sig-param">remove_unicode_entities=False</em>, <em class="sig-param">remove_urls=False</em>, <em class="sig-param">remove_hashtags=False</em>, <em class="sig-param">split_hashtags=False</em>, <em class="sig-param">remove_retweet_prefix=False</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner" title="Permalink to this definition">¶</a></dt>
<dd><p>The tweet cleaner removes needless information from a text to make it presentable.
This includes retweet syntax and URLs.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>remove_unicode_entities</strong> (<em>bool</em>) – A boolean indicating whether unicode entities should be removed.
Note that this also includes emojis.</p></li>
<li><p><strong>remove_urls</strong> (<em>bool</em>) – A boolean indicating whether URLs should be removed.</p></li>
<li><p><strong>remove_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags that cannot be split should be removed.</p></li>
<li><p><strong>split_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags should be split.</p></li>
<li><p><strong>remove_retweet_prefix</strong> (<em>bool</em>) – A boolean indicating whether the retweet prefix should be removed.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">remove_unicode_entities=False</em>, <em class="sig-param">remove_urls=False</em>, <em class="sig-param">remove_hashtags=False</em>, <em class="sig-param">split_hashtags=False</em>, <em class="sig-param">remove_retweet_prefix=False</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Create the tweet cleaner.</p>
<p>The same configuration accepted by the <a class="reference internal" href="#nlp.cleaners.cleaner.Cleaner" title="nlp.cleaners.cleaner.Cleaner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Cleaner</span></code></a> are accepted as arguments and keyword arguments.
They are then passed on to the parent constructor, <a class="reference internal" href="#nlp.cleaners.cleaner.Cleaner.__init__" title="nlp.cleaners.cleaner.Cleaner.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>remove_unicode_entities</strong> (<em>bool</em>) – A boolean indicating whether unicode entities should be removed.
Note that this also includes emojis.</p></li>
<li><p><strong>remove_urls</strong> (<em>bool</em>) – A boolean indicating whether URLs should be removed.</p></li>
<li><p><strong>remove_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags that cannot be split should be removed.</p></li>
<li><p><strong>split_hashtags</strong> (<em>bool</em>) – A boolean indicating whether hashtags should be split.</p></li>
<li><p><strong>remove_retweet_prefix</strong> (<em>bool</em>) – A boolean indicating whether the retweet prefix should be removed.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner.clean">
<code class="sig-name descname">clean</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner.clean" title="Permalink to this definition">¶</a></dt>
<dd><p>Clean the given text.
The basic cleaner always strips empty whitespaces before any pre-processing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The cleaned text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner._remove_unicode_entities">
<code class="sig-name descname">_remove_unicode_entities</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner._remove_unicode_entities" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove unicode entities, including emojis, from the given text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The tweet to be cleaned.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The tweet without unicode entities.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner._remove_urls">
<code class="sig-name descname">_remove_urls</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner._remove_urls" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove Twitter short URLs from the text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean().</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The text without URLs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner._split_hashtags">
<code class="sig-name descname">_split_hashtags</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner._split_hashtags" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the hashtags in the given text based on camel-case notation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to normalize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The text with split hashtags.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner._remove_hashtags">
<code class="sig-name descname">_remove_hashtags</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner._remove_hashtags" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove hashtags from the given text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The text without any hashtags.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nlp.cleaners.tweet_cleaner.TweetCleaner._remove_retweet_prefix">
<code class="sig-name descname">_remove_retweet_prefix</code><span class="sig-paren">(</span><em class="sig-param">text</em><span class="sig-paren">)</span><a class="headerlink" href="#nlp.cleaners.tweet_cleaner.TweetCleaner._remove_retweet_prefix" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove retweet syntax from a tweet.
Retweets start with the text ‘RT &#64;user: ‘</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> (<em>str</em>) – The text to clean.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The cleaned text.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="wikinterface.html" class="btn btn-neutral float-right" title="4. Wikinterface" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="vsm.html" class="btn btn-neutral float-left" title="2. Vector Space Model (VSM)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Nicholas Mamo

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>