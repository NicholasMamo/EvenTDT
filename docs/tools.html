

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="Tools to collect corpora and create timelines out of events." name="description" />
<meta content="Python, TDT, events, Twitter" name="keywords" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>1. Tools &mdash; EvenTDT 0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2. Vector Space Model (VSM)" href="vsm.html" />
    <link rel="prev" title="0. Configuration" href="config.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> EvenTDT
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="config.html">0. Configuration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. Tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-tools.collect">Data Collection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tools.idf">TF-IDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tools.consume">Consumption</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vsm.html">2. Vector Space Model (VSM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlp.html">3. Natural Language Processing (NLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="wikinterface.html">4. Wikinterface</a></li>
<li class="toctree-l1"><a class="reference internal" href="apd.html">5. Automatic Participant Detection (APD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tdt.html">6. Topic Detection and Tracking (TDT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="summarization.html">7. Summarization</a></li>
<li class="toctree-l1"><a class="reference internal" href="twitter.html">8. Twitter</a></li>
<li class="toctree-l1"><a class="reference internal" href="consumers.html">9. Consumers</a></li>
<li class="toctree-l1"><a class="reference internal" href="other.html">10. Other</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">EvenTDT</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>1. Tools</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/tools.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tools">
<h1>1. Tools<a class="headerlink" href="#tools" title="Permalink to this headline">¶</a></h1>
<p>EvenTDT comes with tools to help you collect corpora from Twitter and create timelines from them.
Keep reading to learn more about the different tools available in EvenTDT.</p>
<span class="target" id="module-tools"></span><div class="section" id="module-tools.collect">
<span id="data-collection"></span><h2>Data Collection<a class="headerlink" href="#module-tools.collect" title="Permalink to this headline">¶</a></h2>
<p>A tool to collect tweets.</p>
<p>The tool collects a corpus of tweets.
Each event, described by the first tracking keyword, has its own directory.
All related corpora are stored together in this directory.
Each corpus is a JSON file, where each line is one tweet.</p>
<p>To run the script, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./tools/collect.py <span class="se">\</span>
    -t <span class="s1">&#39;#ARSWAT&#39;</span> Arsenal Watford <span class="se">\</span>
    -o data <span class="se">\</span>
    -U -u <span class="m">60</span> <span class="se">\</span>
    -E -e <span class="m">60</span>
</pre></div>
</div>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">--track</span></code>                        <em>&lt;Required&gt;</em> A list of tracking keywords.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">--output</span></code>                       <em>&lt;Required&gt;</em> The data directory where the corpus should be written.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-u</span> <span class="pre">--understanding</span></code>        <em>&lt;Optional&gt;</em> The length of the understanding period in minutes. Defaults to an hour and must be a natural number.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">--event</span></code>                        <em>&lt;Optional&gt;</em> The length of the event period in minutes. Defaults to an hour and must be a natural number.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-a</span> <span class="pre">--account</span></code>                      <em>&lt;Optional&gt;</em> The account to use to collect the corpus with, as an index of the configuration’s accounts. Defaults to the first account.</p></li>
</ul>
</div></blockquote>
<p>The implemented modes of operation are:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-U</span></code>                                        <em>&lt;Optional&gt;</em> Collect the understanding corpus.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-E</span></code>                                        <em>&lt;Optional&gt;</em> Collect the event corpus.</p></li>
</ul>
</div></blockquote>
<dl class="function">
<dt id="tools.collect.setup_args">
<code class="sig-name descname">setup_args</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.collect.setup_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Set up and get the list of command-line arguments.</p>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">--track</span></code>                        <em>&lt;Required&gt;</em> A list of tracking keywords.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">--output</span></code>                       <em>&lt;Required&gt;</em> The data directory where the corpus should be written.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-U</span></code>                                        <em>&lt;Optional&gt;</em> Collect the understanding corpus.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-u</span> <span class="pre">--understanding</span></code>        <em>&lt;Optional&gt;</em> The length of the understanding period in minutes. Defaults to an hour and must be a natural number.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-E</span></code>                                        <em>&lt;Optional&gt;</em> Collect the event corpus.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-e</span> <span class="pre">--event</span></code>                        <em>&lt;Optional&gt;</em> The length of the event period in minutes. Defaults to an hour and must be a natural number.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-a</span> <span class="pre">--account</span></code>                      <em>&lt;Optional&gt;</em> The account to use to collect the corpus with, as an index of the configuration’s accounts. Defaults to the first account.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The command-line arguments.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.collect.main">
<code class="sig-name descname">main</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.collect.main" title="Permalink to this definition">¶</a></dt>
<dd><p>Main program loop.</p>
</dd></dl>

<dl class="function">
<dt id="tools.collect.collect">
<code class="sig-name descname">collect</code><span class="sig-paren">(</span><em class="sig-param">auth</em>, <em class="sig-param">track</em>, <em class="sig-param">filename</em>, <em class="sig-param">max_time</em>, <em class="sig-param">lang=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.collect.collect" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect tweets and save them to the given file.
The tweets are collected synchronously.
Any additional arguments or keyword arguments are passed on to the <code class="xref py py-class docutils literal notranslate"><span class="pre">twitter.twevent.listener.TweetListener</span></code> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>auth</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tweepy.OAuthHandler</span></code>) – The OAuth handler to connect with Twitter’s API.</p></li>
<li><p><strong>track</strong> (<em>list of str</em>) – The tracking keywords:</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – The filename where to save the collected tweets.</p></li>
<li><p><strong>max_time</strong> (<em>int</em>) – The number of seconds to spend collecting tweets.</p></li>
<li><p><strong>lang</strong> (<em>list of str</em>) – The tweet collection language, defaults to English.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.collect.save_meta">
<code class="sig-name descname">save_meta</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">meta</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.collect.save_meta" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the metadata of the collected datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) – The filename where to write the metadata.</p></li>
<li><p><strong>meta</strong> (<em>list of dict</em>) – The metadata to save.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-tools.sample"></span><p>A tool to collect tweets using the Sampling API.</p>
<p>The tool collects a corpus of tweets.
Each collection has its own directory.
Each corpus is a JSON file, where each line is one tweet.</p>
<p>To run the script, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./tools/sample.py <span class="se">\</span>
    -o data/sample <span class="se">\</span>
    -t <span class="m">60</span>
</pre></div>
</div>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">--time</span></code>         <em>&lt;Required&gt;</em> The time to spend collecting tweets in minutes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">--output</span></code>       <em>&lt;Required&gt;</em> The data directory where the corpus should be written.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-a</span> <span class="pre">--account</span></code>      <em>&lt;Optional&gt;</em> The account to use to collect the corpus with, as an index of the configuration’s accounts. Defaults to the first account.</p></li>
</ul>
</div></blockquote>
<dl class="function">
<dt id="tools.sample.setup_args">
<code class="sig-name descname">setup_args</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.sample.setup_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Set up and get the list of command-line arguments.</p>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-t</span> <span class="pre">--time</span></code>         <em>&lt;Required&gt;</em> The time to spend collecting tweets in minutes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">--output</span></code>       <em>&lt;Required&gt;</em> The data directory where the corpus should be written.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-a</span> <span class="pre">--account</span></code>      <em>&lt;Optional&gt;</em> The account to use to collect the corpus with, as an index of the configuration’s accounts. Defaults to the first account.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The command-line arguments.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.sample.main">
<code class="sig-name descname">main</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.sample.main" title="Permalink to this definition">¶</a></dt>
<dd><p>Main program loop.</p>
</dd></dl>

<dl class="function">
<dt id="tools.sample.collect">
<code class="sig-name descname">collect</code><span class="sig-paren">(</span><em class="sig-param">auth</em>, <em class="sig-param">filename</em>, <em class="sig-param">max_time</em>, <em class="sig-param">lang=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.sample.collect" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect tweets and save them to the given file.
The tweets are collected synchronously.
Any additional arguments or keyword arguments are passed on to the <code class="xref py py-class docutils literal notranslate"><span class="pre">twitter.twevent.listener.TweetListener</span></code> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>auth</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">tweepy.OAuthHandler</span></code>) – The OAuth handler to connect with Twitter’s API.</p></li>
<li><p><strong>filename</strong> (<em>str</em>) – The filename where to save the collected tweets.</p></li>
<li><p><strong>max_time</strong> (<em>int</em>) – The number of seconds to spend collecting tweets.</p></li>
<li><p><strong>lang</strong> (<em>list of str</em>) – The tweet collection language, defaults to English.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.sample.save_meta">
<code class="sig-name descname">save_meta</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">meta</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.sample.save_meta" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the metadata of the collected dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) – The filename where to write the metadata.</p></li>
<li><p><strong>meta</strong> (<em>list of dict</em>) – The metadata to save.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tools.idf">
<span id="tf-idf"></span><h2>TF-IDF<a class="headerlink" href="#module-tools.idf" title="Permalink to this headline">¶</a></h2>
<p>A tool to create a TF-IDF scheme from a corpus of tweets.</p>
<p>To run the script, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./implementation/idf.py <span class="se">\</span>
    -f data/sample.json <span class="se">\</span>
    -o data/idf.json <span class="se">\</span>
    --remove-unicode-entities
    --normalize-words --stem
</pre></div>
</div>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-f</span> <span class="pre">--file</span></code>                                                 <em>&lt;Required&gt;</em> The file to use to construct the TF-IDF scheme.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">--output</span></code>                                               <em>&lt;Required&gt;</em> The file where to save the TF-IDF scheme.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--remove-unicode-entities</span></code>                 <em>&lt;Optional&gt;</em> Remove unicode entities from the TF-IDF scheme.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--normalize-words</span></code>                                 <em>&lt;Optional&gt;</em> Normalize words with repeating characters in them.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--character-normalization-count</span></code>   <em>&lt;Optional&gt;</em> The number of times a character must repeat for it to be normalized. Used only with the <code class="docutils literal notranslate"><span class="pre">--normalize-words</span></code> flag.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-stem</span></code>                                                             <em>&lt;Optional&gt;</em> Stem the tokens when constructing the TF-IDF scheme.</p></li>
</ul>
</div></blockquote>
<dl class="function">
<dt id="tools.idf.setup_args">
<code class="sig-name descname">setup_args</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.idf.setup_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Set up and get the list of command-line arguments.</p>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-f</span> <span class="pre">--file</span></code>                                                 <em>&lt;Required&gt;</em> The file to use to construct the TF-IDF scheme.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">--output</span></code>                                               <em>&lt;Required&gt;</em> The file where to save the TF-IDF scheme.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--remove-unicode-entities</span></code>                 <em>&lt;Optional&gt;</em> Remove unicode entities from the TF-IDF scheme.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--normalize-words</span></code>                                 <em>&lt;Optional&gt;</em> Normalize words with repeating characters in them.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--character-normalization-count</span></code>   <em>&lt;Optional&gt;</em> The number of times a character must repeat for it to be normalized. Used only with the <code class="docutils literal notranslate"><span class="pre">--normalize-words</span></code> flag.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--stem</span></code>                                                    <em>&lt;Optional&gt;</em> Stem the tokens when constructing the TF-IDF scheme.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The command-line arguments.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.idf.main">
<code class="sig-name descname">main</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.idf.main" title="Permalink to this definition">¶</a></dt>
<dd><p>Main program loop.</p>
</dd></dl>

<dl class="function">
<dt id="tools.idf.construct">
<code class="sig-name descname">construct</code><span class="sig-paren">(</span><em class="sig-param">file</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.idf.construct" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the TF-IDF scheme from the file.
The scheme is constructed one line at a time.</p>
<p>Any additional arguments and keyword arguments are passed on to the <a class="reference internal" href="nlp.html#nlp.tokenizer.Tokenizer.__init__" title="nlp.tokenizer.Tokenizer.__init__"><code class="xref py py-func docutils literal notranslate"><span class="pre">__init__()</span></code></a> constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file</strong> (<em>str</em>) – The path to the file to use to construct the TF-IDF scheme.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The TF-IDF scheme constructed from the file.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="nlp.html#nlp.term_weighting.tfidf.TFIDF" title="nlp.term_weighting.tfidf.TFIDF"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFIDF</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.idf.tokenize">
<code class="sig-name descname">tokenize</code><span class="sig-paren">(</span><em class="sig-param">tweet</em>, <em class="sig-param">tokenizer</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.idf.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the given tweet into a document.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tweet</strong> (<em>dict</em>) – The tweet to tokenize.</p></li>
<li><p><strong>tokenizer</strong> (<a class="reference internal" href="nlp.html#nlp.tokenizer.Tokenizer" title="nlp.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tokenizer</span></code></a>) – The tokenizer to use to tokenize the tweet.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of tokens from the tweet.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.idf.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">idf</em>, <em class="sig-param">tokens</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.idf.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the given IDF table with the given tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idf</strong> (<em>dict</em>) – The IDF table as a dictionary.
The keys are the tokens and the values are the document frequencies.</p></li>
<li><p><strong>tokens</strong> – The tokens to add to the IDF.
The function automatically gets the set of tokens to remove duplicates.</p></li>
</ul>
</dd>
<dt class="field-even">Type</dt>
<dd class="field-even"><p>list of str</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The updated IDF table.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.idf.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">tfidf</em>, <em class="sig-param">output</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.idf.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the given TF-IDF scheme to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tfidf</strong> – The TF-IDF scheme.</p></li>
<li><p><strong>output</strong> (<em>str</em>) – The path to the file where to save the TF-IDF scheme.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-tools.consume">
<span id="consumption"></span><h2>Consumption<a class="headerlink" href="#module-tools.consume" title="Permalink to this headline">¶</a></h2>
<p>The consumer receives an input file and consumes it with one of the given consumers.
This consumer is split into two asynchronous tasks.
The first task reads the file, and the second consumes it.</p>
<p>If an understanding file is provided, it is used for the understanding task.
The process is similar to before, with two asynchronous tasks.
The first task reads the file, and the second consumes it, this time to understand the event.</p>
<p>All dataset files are expected to contain one tweet on every line, encoded as JSON strings.</p>
<p>To run the script, use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./implementation/consume.py <span class="se">\</span>
    -f data/event/event.json <span class="se">\</span>
    -c PrintConsumer
</pre></div>
</div>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-f</span> <span class="pre">--file</span></code>                                 <em>&lt;Required&gt;</em> The file to consume.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-c</span> <span class="pre">--class</span></code>                                <em>&lt;Required&gt;</em> The consumer to use; supported: <cite>ELDConsumer</cite>, <cite>FIREConsumer</cite>, <cite>PrintConsumer</cite>, <cite>StatConsumer</cite>, <cite>ZhaoConsumer</cite>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-u</span> <span class="pre">--understanding</span></code>                <em>&lt;Optional&gt;</em> The understanding file used to understand the event.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">--speed</span></code>                                <em>&lt;Optional&gt;</em> The speed at which the file is consumed, defaults to 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--skip</span></code>                                    <em>&lt;Optional&gt;</em> The amount of time to skip from the beginning of the file in minutes, defaults to 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--no-cache</span></code>                                <em>&lt;Optional&gt;</em> If specified, the cached understanding is not used. The new understanding is cached instead.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--scheme</span></code>                                  <em>&lt;Optional&gt;</em> If specified, the path to the <a class="reference internal" href="nlp.html#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a> to use. If it is not specified, the <a class="reference internal" href="nlp.html#nlp.term_weighting.tf.TF" title="nlp.term_weighting.tf.TF"><code class="xref py py-class docutils literal notranslate"><span class="pre">TF</span></code></a> scheme is used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--min-size</span></code>                                <em>&lt;Optional&gt;</em> The minimum number of tweets in a cluster to consider it as a candidate topic, defaults to 3.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--threshold</span></code>                               <em>&lt;Optional&gt;</em> The minimum similarity between a tweet and a cluster to add the tweet to the cluster, defaults to 0.5.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--max-intra-similarity</span></code>    <em>&lt;Optional&gt;</em> The maximum intra-similarity of documents in a cluster to consider it as a candidate topic, defaults to 0.8.</p></li>
</ul>
</div></blockquote>
<dl class="function">
<dt id="tools.consume.setup_args">
<code class="sig-name descname">setup_args</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.setup_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Set up and get the list of command-line arguments.</p>
<p>Accepted arguments:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-f</span> <span class="pre">--file</span></code>                                 <em>&lt;Required&gt;</em> The file to consume.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-c</span> <span class="pre">--class</span></code>                                <em>&lt;Required&gt;</em> The consumer to use; supported: <cite>ELDConsumer</cite>, <cite>FIREConsumer</cite>, <cite>PrintConsumer</cite>, <cite>StatConsumer</cite>, <cite>ZhaoConsumer</cite>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-u</span> <span class="pre">--understanding</span></code>                <em>&lt;Optional&gt;</em> The understanding file used to understand the event.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-s</span> <span class="pre">--speed</span></code>                                <em>&lt;Optional&gt;</em> The speed at which the file is consumed, defaults to 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--no-cache</span></code>                                <em>&lt;Optional&gt;</em> If specified, the cached understanding is not used. The new understanding is cached instead.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--skip</span></code>                                    <em>&lt;Optional&gt;</em> The amount of time to skip from the beginning of the file in minutes, defaults to 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--scheme</span></code>                                  <em>&lt;Optional&gt;</em> If specified, the path to the <a class="reference internal" href="nlp.html#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a> to use. If it is not specified, the <a class="reference internal" href="nlp.html#nlp.term_weighting.tf.TF" title="nlp.term_weighting.tf.TF"><code class="xref py py-class docutils literal notranslate"><span class="pre">TF</span></code></a> scheme is used. This can be overwritten if there is event understanding.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--min-size</span></code>                                <em>&lt;Optional&gt;</em> The minimum number of tweets in a cluster to consider it as a candidate topic, defaults to 3.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--threshold</span></code>                               <em>&lt;Optional&gt;</em> The minimum similarity between a tweet and a cluster to add the tweet to the cluster, defaults to 0.5.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--max-intra-similarity</span></code>    <em>&lt;Optional&gt;</em> The maximum intra-similarity of documents in a cluster to consider it as a candidate topic, defaults to 0.8.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The command-line arguments.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.main">
<code class="sig-name descname">main</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.main" title="Permalink to this definition">¶</a></dt>
<dd><p>Main program loop.</p>
</dd></dl>

<dl class="function">
<dt id="tools.consume.meta">
<code class="sig-name descname">meta</code><span class="sig-paren">(</span><em class="sig-param">args</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.meta" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the meta arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">argparse.Namespace</span></code>) – The command-line arguments.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The meta arguments as a dictionary.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.understand">
<code class="sig-name descname">understand</code><span class="sig-paren">(</span><em class="sig-param">understanding</em>, <em class="sig-param">consumer</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.understand" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the understanding process.
The arguments and keyword arguments should be the command-line arguments.</p>
<p>Understanding uses two processes:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Stream the file, and</p></li>
<li><p>Understand the file.</p></li>
</ol>
</div></blockquote>
<p>Both processes share the same event loop and queue.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Understanding is sped up, on the assumption that processing is done retrospectively.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>understanding</strong> (<em>str</em>) – The path to the file containing the event’s understanding.</p></li>
<li><p><strong>consumer</strong> (<a class="reference internal" href="consumers.html#queues.consumers.consumer.Consumer" title="queues.consumers.consumer.Consumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Consumer</span></code></a>) – The type of consumer to use.</p></li>
<li><p><strong>scheme</strong> (<a class="reference internal" href="nlp.html#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a>) – The scheme to use when consuming the file.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary containing the understanding.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.consume">
<code class="sig-name descname">consume</code><span class="sig-paren">(</span><em class="sig-param">file</em>, <em class="sig-param">consumer</em>, <em class="sig-param">speed</em>, <em class="sig-param">scheme=None</em>, <em class="sig-param">skip=0</em>, <em class="sig-param">min_size=3</em>, <em class="sig-param">threshold=0.5</em>, <em class="sig-param">max_intra_similarity=0.8</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.consume" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the consumption process.
The arguments and keyword arguments should be the command-line arguments.</p>
<p>Consumption uses two processes:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Stream the file, and</p></li>
<li><p>Consume the file.</p></li>
</ol>
</div></blockquote>
<p>Both processes share the same event loop and queue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file</strong> (<em>str</em>) – The path to the file containing the event’s tweets.</p></li>
<li><p><strong>consumer</strong> (<a class="reference internal" href="consumers.html#queues.consumers.consumer.Consumer" title="queues.consumers.consumer.Consumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Consumer</span></code></a>) – The type of consumer to use.</p></li>
<li><p><strong>speed</strong> (<em>float</em>) – The speed with which to read the file.</p></li>
<li><p><strong>scheme</strong> (<a class="reference internal" href="nlp.html#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a>) – The scheme to use when consuming the file.</p></li>
<li><p><strong>skip</strong> (<em>int</em>) – The amount of time to skip from the beginning of the file in minutes, defaults to 0.</p></li>
<li><p><strong>min_size</strong> (<em>int</em>) – The minimum number of tweets in a cluster to consider it as a candidate topic, defaults to 3.</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – The minimum similarity between a tweet and a cluster to add the tweet to the cluster, defaults to 0.5.</p></li>
<li><p><strong>max_intra_similarity</strong> (<em>float</em>) – The maximum intra-similarity of documents in a cluster to consider it as a candidate topic, defaults to 0.8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A dictionary containing the timeline.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.stream_process">
<code class="sig-name descname">stream_process</code><span class="sig-paren">(</span><em class="sig-param">loop</em>, <em class="sig-param">queue</em>, <em class="sig-param">file</em>, <em class="sig-param">skip_time=0</em>, <em class="sig-param">speed=1</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.stream_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Stream the file and add its tweets to the queue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loop</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">asyncio.unix_events._UnixSelectorEventLoop</span></code>) – The main event loop.</p></li>
<li><p><strong>queue</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">multiprocessing.managers.AutoProxy[Queue]</span></code>) – The queue where to add tweets.</p></li>
<li><p><strong>file</strong> (<em>str</em>) – The path to the file to read.</p></li>
<li><p><strong>skip_time</strong> (<em>int</em>) – The amount of time to skip from the beginning of the file in minutes, defaults to 0.</p></li>
<li><p><strong>speed</strong> (<em>float</em>) – The speed at which the file is consumed, defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.understand_process">
<code class="sig-name descname">understand_process</code><span class="sig-paren">(</span><em class="sig-param">comm</em>, <em class="sig-param">loop</em>, <em class="sig-param">consumer</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.understand_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Consume the incoming tweets to understand the event.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>comm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">multiprocessing.managers.DictProxy</span></code>) – The dictionary used by the understanding process to communicate data back to the main loop.</p></li>
<li><p><strong>loop</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">asyncio.unix_events._UnixSelectorEventLoop</span></code>) – The main event loop.</p></li>
<li><p><strong>consumer</strong> (<a class="reference internal" href="consumers.html#queues.consumers.consumer.Consumer" title="queues.consumers.consumer.Consumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Consumer</span></code></a>) – The consumer to use to process tweets.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.consume_process">
<code class="sig-name descname">consume_process</code><span class="sig-paren">(</span><em class="sig-param">comm</em>, <em class="sig-param">loop</em>, <em class="sig-param">consumer</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.consume_process" title="Permalink to this definition">¶</a></dt>
<dd><p>Consume the incoming tweets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>comm</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">multiprocessing.managers.DictProxy</span></code>) – The dictionary used by the consumption process to communicate data back to the main loop.</p></li>
<li><p><strong>loop</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">asyncio.unix_events._UnixSelectorEventLoop</span></code>) – The main event loop.</p></li>
<li><p><strong>consumer</strong> (<a class="reference internal" href="consumers.html#queues.consumers.consumer.Consumer" title="queues.consumers.consumer.Consumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Consumer</span></code></a>) – The consumer to use to process tweets.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.cache_exists">
<code class="sig-name descname">cache_exists</code><span class="sig-paren">(</span><em class="sig-param">file</em>, <em class="sig-param">cache_dir='.cache'</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.cache_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>Check whether cache exists for the given file.
The cache exists in a cache directory and has the same name as the given file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file</strong> (<em>str</em>) – The path to the file whose cache will be sought.</p></li>
<li><p><strong>cache_dir</strong> – The directory where cache is stored.
This is relative to the file’s directory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A boolean indicating whether cache exists for the given file.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">file</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the data to the given file.
The function saves the data as a JSON file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file</strong> (<em>str</em>) – The path to the file where to save the data.</p></li>
<li><p><strong>data</strong> (<em>dict</em>) – The data to save.
The function expects a dictionary that can be JSON serializable.
The function tries to convert the values that cannot be serialized to arrays.
Only classes that inherit the <a class="reference internal" href="other.html#objects.exportable.Exportable" title="objects.exportable.Exportable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Exportable</span></code></a> can be converted to arrays.
This is done through the <a class="reference internal" href="other.html#objects.exportable.Exportable.to_array" title="objects.exportable.Exportable.to_array"><code class="xref py py-func docutils literal notranslate"><span class="pre">to_array()</span></code></a> function.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">file</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the data from the given file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file</strong> (<em>str</em>) – The path to the file from where to load the data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A new dictionary with the loaded data.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.consumer">
<code class="sig-name descname">consumer</code><span class="sig-paren">(</span><em class="sig-param">consumer</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.consumer" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert the given string into a consumer class.
The accepted consumers are:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><a class="reference internal" href="consumers.html#queues.consumers.eld_consumer.ELDConsumer" title="queues.consumers.eld_consumer.ELDConsumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ELDConsumer</span></code></a>,</p></li>
<li><p><a class="reference internal" href="consumers.html#queues.consumers.fire_consumer.FIREConsumer" title="queues.consumers.fire_consumer.FIREConsumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">FIREConsumer</span></code></a>,</p></li>
<li><p><a class="reference internal" href="consumers.html#queues.consumers.print_consumer.PrintConsumer" title="queues.consumers.print_consumer.PrintConsumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PrintConsumer</span></code></a>,</p></li>
<li><p><a class="reference internal" href="consumers.html#queues.consumers.stat_consumer.StatConsumer" title="queues.consumers.stat_consumer.StatConsumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">StatConsumer</span></code></a>, and</p></li>
<li><p><a class="reference internal" href="consumers.html#queues.consumers.zhao_consumer.ZhaoConsumer" title="queues.consumers.zhao_consumer.ZhaoConsumer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ZhaoConsumer</span></code></a></p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>consumer</strong> (<em>str</em>) – The consumer string.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The class that corresponds to the given consumer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>class</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>argparse.ArgumentTypeError</strong> – When the given consumer string is invalid.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="tools.consume.scheme">
<code class="sig-name descname">scheme</code><span class="sig-paren">(</span><em class="sig-param">file</em><span class="sig-paren">)</span><a class="headerlink" href="#tools.consume.scheme" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the term-weighting scheme from the given file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file</strong> (<em>str</em>) – The path to the term-weighting scheme.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The term-weighting scheme in the given file.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="nlp.html#nlp.term_weighting.scheme.TermWeightingScheme" title="nlp.term_weighting.scheme.TermWeightingScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">TermWeightingScheme</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="vsm.html" class="btn btn-neutral float-right" title="2. Vector Space Model (VSM)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="config.html" class="btn btn-neutral float-left" title="0. Configuration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Nicholas Mamo

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>